### 爬取水果派

作为一个老色批，自然要拿这个网站来练练手。首先我们检查页面源代码，就能发现有一个`m3u8`文件，不过有一点点小加密。打开这个`m3u8`后发现就一个网址，把这个网址和域名拼接后才得到我们最终需要的`m3u8`，然后就是拿着这个`m3u8`去下载ts文件，然后合并。

话不多说，我们开整。

### 步骤

#### 通过`url`获取最终的`m3u8`文件

```python
obj = re.compile(r'type:[a-z],url:"(?P<first_url>.*?)",', re.S)

def get_m3u8(url):
    resp = requests.get(url)
    resp.encoding = 'utf-8'
    # 正则匹配得到m3u8
    try:
        first_url = obj.search(resp.text).group("first_url")
    except AttributeError:
        print(url + "下载失败")
        return None
    else:
        # print(first_url)
        resp.close()
        # 这里解密一下，就是一个小小的替换
        first_url = first_url.replace("\\u002F", "/")
        resp2 = requests.get(first_url)
        # 获取第一层m3u8文件
        with open("sgp.m3u8", mode="wb") as f:
            f.write(resp2.content)
        f.close()
        resp2.close()
        # 打开刚刚得到的文件，获取url
        with open("sgp.m3u8", mode="r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line.startswith("#"):
                    continue
                end = line
        f.close()
        # 拼接得到最终的m3u8文件的url
        final_url = first_url.rsplit("/", 1)[0] + "/" + end
        # print(final_url)
        resp3 = requests.get(final_url)
        # 获取真正的m3u8文件
        with open("sgp.m3u8", mode="wb") as f:
            f.write(resp3.content)
        f.close()
        resp3.close()
        print("m3u8下载完毕！")
        return final_url
```

#### 获取每一个ts文件的下载地址

```python
def download_ts(final_url):
    ts_urls = []
    with open("sgp.m3u8", mode="r", encoding="utf-8") as f:
        for line in f:
            line.strip()
            if line.startswith("#"):
                continue
            # 凭借得到最终的地址
            ts_url = final_url.rsplit("/", 1)[0] + "/" + line
            ts_urls.append(ts_url.strip())
    f.close()
    return ts_urls
```

#### 下载一个ts文件

需要为每一个ts文件命名，这样就方便我们合并ts。

```python
def down_ts_url(ts_url, name):
    # print(ts_url)
    resp4 = requests.get(ts_url)
    f = open(name, mode="wb")
    f.write(resp4.content)
    f.close()
    resp4.close()
    # print(f"完成了{name}")
```

#### 合并ts文件

注意copy命令一次最多合并300个文件，如果多于300个需要分开合并。

```python
def merge_ts(count, n):
    lst = []
    for i in range(1, n + 1):
        lst.append(f"{i}.ts")
        # print(lst[i])
    s = "+".join(lst)
    # print(s)
    name = f"{count}.mp4"
    # 这个命令一次最多合并300个文件，正好，水果派视频不长，够用了
    os.system(f"copy /b {s} {name}")
    for i in range(1, n + 1):
        os.remove(f"{i}.ts")
        # 删除ts文件，只保留我们需要的mp4文件
    print("合并完毕")
```

#### main函数

```python
def main():
    root_url = "https://sgptv.cc/play-details/1/"
    t1 = time.time()
    for i in range(389, 390):
        url = root_url + str(i)
        final_url = get_m3u8(url)
        if final_url == None:
            continue
        ts_urls = download_ts(final_url)
        n = 0	# 用来给多个ts文件命名
        # 多线程下载，加快速度
        with ThreadPoolExecutor(100) as t:
            for ts_url in ts_urls:
                n += 1
                t.submit(down_ts_url, ts_url, name=f"{n}.ts")
        print("下载ts完毕")
        merge_ts(i, n)
    t2 = time.time()
    print(t2 - t1)
```

### 来吧展示

![image-20211026113058704](C:\Users\pikachu\AppData\Roaming\Typora\typora-user-images\image-20211026113058704.png)

